apiVersion: apps/v1
kind: Deployment
metadata:
  name: triton-custom
  namespace: monitoring
  labels:
    app: triton-custom
spec:
  replicas: 3
  selector:
    matchLabels:
      app: triton-custom
  template:
    metadata:
      labels:
        app: triton-custom
    spec:
      volumes:
      - name: workspace
        hostPath:
          path: /mnt/data/bangpc/test_triton
      - name: shm
        emptyDir:
          medium: Memory
        # nfs:
        #   server: 192.168.0.231
        #   path: /media/Data/bangpc/nfs_volume/triton_repo/fd_repo
        #   readOnly: false
      containers:
        - name: triton-custom
          ports:
          - containerPort: 8000
            name: http-triton
          - containerPort: 8001
            name: grpc-triton
          - containerPort: 8002
            name: metrics-triton
          image: "tritonserver:22.08-py3-custom"
          volumeMounts:
          - mountPath: /workspace
            name: workspace
          - mountPath: /dev/shm
            name: shm
          command: ["/bin/sh", "-c"]
          args: ["/opt/tritonserver/bin/tritonserver --model-repository=/workspace/triton_repo --strict-model-config=false"]
            # nodeSelector:
            #   tag: gpu_worker

---

apiVersion: v1
kind: Service
metadata:
  name: triton-custom
  namespace: monitoring
  labels:
    app: triton-custom
spec:
  selector:
    app: triton-custom
  ports:
    - protocol: TCP
      port: 8000
      name: http
      targetPort: 8000
      nodePort: 32000
    - protocol: TCP
      port: 8001
      name: grpc
      targetPort: 8001
      nodePort: 32001
    - protocol: TCP
      port: 8002
      name: metrics
      targetPort: 8002
      nodePort: 32002
  type: LoadBalancer 
  loadBalancerIP: 192.168.0.100
